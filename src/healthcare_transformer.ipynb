{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2d960a9d",
   "metadata": {},
   "source": [
    "Autoregressive model that utilizes the decoder transformer architecture using the Keras/Tensor framework. In laymens terms we want to train a model similar to chat gpt, however instead of training on natural language we will use a patients life long healthcare journey through diagnosis codes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6d793f1",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "63689635",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, losses, callbacks\n",
    "from fn_data_prep import create_sequences\n",
    "from keras import ops\n",
    "import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b755d1e1",
   "metadata": {},
   "source": [
    "We use synthetic claims data to create a sequence ordered by date to mimic a typical text based corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "97252e19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            patient      date    dx\n",
      "0  00013D2EFD8E45D1  20100312  7802\n",
      "1  00016F745862898F  20090412  1970\n",
      "2  00016F745862898F  20090831  6186\n",
      "Created 15140 patient sequences\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['6826 485 4589 7211 49122',\n",
       " '40291 43491 42731 99662 99662',\n",
       " '4271 4372 43491 481 41401',\n",
       " '49122 49121 78906 4280 7802 27651 5990 5070',\n",
       " '25072 5070 25061 99674 99662',\n",
       " '49121 42731 1977 486 40390',\n",
       " '5609 6820 3310 99664 7802 1983',\n",
       " '9962 49121 49322 1363 V5789 41071',\n",
       " '5990 179 2809 V5789 27651',\n",
       " '51881 2841 29620 29634 00845 5722 29281 29570 29650 29212 29689',\n",
       " '920 8208 51881 4280 03849 42731 49121',\n",
       " '7230 53150 4414 4414 44030 6826',\n",
       " '71595 2112 2859 56722 56213',\n",
       " '486 41071 41071 2111 4240',\n",
       " '29532 0389 0088 5070 29680 5990 42789 43491',\n",
       " '42731 72633 7336 1623 29530',\n",
       " '9972 43411 49122 4280 56081 42731 78791',\n",
       " '6824 2761 42731 486 28264',\n",
       " '2859 41401 41401 5789 5849',\n",
       " '5849 39891 99662 40391 5609',\n",
       " '7295 486 41071 41071 27651 41401 7837 41519',\n",
       " '486 45341 8404 5110 56212 41071 486',\n",
       " '95208 2800 5070 71535 6826',\n",
       " '2113 2762 71535 71536 5722',\n",
       " '49121 0389 9972 3334 51881 41401 49122',\n",
       " '1629 42731 99664 29534 25061 29570 5589',\n",
       " '7802 41071 51883 7802 3481',\n",
       " '29640 1901 29640 5363 486',\n",
       " '78659 6822 43411 4280 1749 42781',\n",
       " '55011 49322 07999 4359 4280',\n",
       " '8472 42831 0389 5849 57461',\n",
       " '43311 4821 59582 44422 4241 0389 29624',\n",
       " '82021 6826 5109 486 51882 4280 59971 5990 99662 V5789',\n",
       " '99664 4210 42732 V5789 0389 25002 38003 80508',\n",
       " '41401 5609 49392 51881 42830 V5789 71595 486 49121',\n",
       " '49121 56969 78659 9961 99939 78659 42781 49121',\n",
       " '42821 V5789 7211 4275 5849 78659 42823',\n",
       " '71106 51881 99642 49121 00845 41401 41011 8082',\n",
       " '99662 0088 99931 56989 4111 29633 29532 96502 2910 2920',\n",
       " '39891 4241 4280 4280 5761 5693',\n",
       " '44421 2830 59010 49122 25080 41401',\n",
       " '56211 99883 29570 9680 79092 3014 486 78652',\n",
       " '4280 7840 5990 99831 49121 78900 51884',\n",
       " '82101 82021 8505 82101 82020 44021 57470 49122',\n",
       " '5990 51881 55321 4659 29570',\n",
       " '6184 5568 2967 3071 29653',\n",
       " '5119 82021 4111 1977 51881 51881',\n",
       " '78720 29632 78650 V5789 70704',\n",
       " '71535 486 03849 3335 42731 5789',\n",
       " '51881 78903 41401 4280 V5789 29632',\n",
       " 'V5789 27651 44021 99631 51881 48283 V5789',\n",
       " '2749 73008 5184 70705 5570 42823',\n",
       " '42823 0389 27651 42823 20300',\n",
       " 'V5789 4359 7802 20500 5070 59080 0389',\n",
       " '29574 49322 2113 4660 41071 51884 49322 41071 486',\n",
       " '72402 51884 73027 1534 48242 41401',\n",
       " '5070 5070 29532 29654 2967 03842',\n",
       " '57400 82009 5739 41400 99662',\n",
       " '29530 5559 99669 5589 99662 99661 78039 570',\n",
       " '61171 99859 5770 1985 5070',\n",
       " '86330 43491 0389 49121 51881 53783',\n",
       " '03811 99859 5609 4552 5589',\n",
       " '42843 51881 V5789 4414 0389',\n",
       " '7802 27542 99762 4590 78659 42823',\n",
       " '78079 51884 V571 7804 49122',\n",
       " '7230 5533 41401 99859 49121',\n",
       " '99673 41401 486 8246 4414 71536 99832 27651',\n",
       " '45342 460 44022 3569 99673 5849',\n",
       " '5780 78659 0389 70715 49121',\n",
       " '99683 5849 82021 8082 03849',\n",
       " '9974 2761 43491 5959 7812',\n",
       " '1608 41401 99644 4280 20500 71536 40390 42820',\n",
       " '81353 81200 78650 45341 42831 6826',\n",
       " 'V5789 4359 5990 V5789 41519 99674 55321',\n",
       " '71531 43310 71536 41401 5781 51881 486',\n",
       " '51919 44422 V5789 42830 51881',\n",
       " '49121 V5789 4280 V5789 0389 42843',\n",
       " '07999 3453 311 7802 78079 41400',\n",
       " '29570 25080 4280 5789 2113 29181 27651',\n",
       " '43491 49122 V5789 5990 99832 41071',\n",
       " '4918 4280 5119 45342 9974 0389 7907',\n",
       " '5401 56962 1623 2113 5849',\n",
       " 'V5789 99662 42731 7802 4280 45341 4254',\n",
       " '7245 486 41071 99883 42732',\n",
       " '4280 71596 1889 82021 9694',\n",
       " '42823 V5789 0389 5523 7245 5849 5781 25070 40391 25080',\n",
       " '1629 25060 42833 486 41071',\n",
       " '486 73017 45341 5589 99664 99760 42831 2767',\n",
       " '41011 81308 5849 8082 0389',\n",
       " '49121 49122 49122 42789 9678 6202 49121 4280 5712 9698 49322',\n",
       " '5070 43889 25063 7265 41401',\n",
       " '5579 42843 49121 41021 41401 5849',\n",
       " '99859 41091 20285 99674 8082',\n",
       " '486 70705 41071 5070 6825',\n",
       " '7802 4580 71595 59080 42823 5070 42731 0380',\n",
       " '30501 41071 0380 5849 5119',\n",
       " '99649 8054 3004 4232 V5789 85181',\n",
       " '82021 7802 59010 3310 2411',\n",
       " '0388 43411 4210 34831 41071',\n",
       " '3310 78659 5990 49121 5849',\n",
       " '42731 5552 5780 99641 43491 V5811',\n",
       " '9974 78901 29633 486 43889',\n",
       " '7802 V5789 03842 5967 42823',\n",
       " '41401 4280 78791 41011 44021',\n",
       " '43491 311 3453 68100 8500',\n",
       " '71535 V5789 49322 2809 49121',\n",
       " '48283 V5789 25012 40391 5070 3384',\n",
       " '56721 99664 70703 0389 41071 V5789',\n",
       " '42731 57410 34830 99601 94536 6826',\n",
       " '486 486 39891 39891 71591 49121',\n",
       " '4263 03842 1983 29534 0088',\n",
       " '99673 99672 4280 4254 2752 486 40391',\n",
       " '44422 5990 2761 261 4280',\n",
       " '51884 4589 42833 72252 V553 99684',\n",
       " '99663 51881 4359 7802 42731',\n",
       " '515 49322 27651 2989 49121',\n",
       " 'V5789 41071 41401 03842 5990',\n",
       " '82021 V5789 8082 V5789 V5789',\n",
       " '5722 99681 5849 4280 41519',\n",
       " '49392 42821 42731 92411 5789 7802 1830',\n",
       " '5570 44024 32723 41071 41071',\n",
       " '07999 4359 486 42731 42731',\n",
       " '00845 30391 4580 29634 5569 99661 66111 3530',\n",
       " '99811 51884 486 55320 49121',\n",
       " '8052 51889 78900 56211 515 0310',\n",
       " '96502 V5789 4329 51881 5990 2989',\n",
       " '7993 25002 7802 49121 34590 42820 96509',\n",
       " '4280 25060 49121 5789 6826',\n",
       " '0389 5789 20280 0389 92401',\n",
       " '41071 4111 27651 41021 4389 5119',\n",
       " '5070 4280 43491 41091 5990 1983',\n",
       " '5789 29590 42823 7910 49121 42830 42781 51881 42732',\n",
       " '8500 3315 44101 486 1749 03811 56211',\n",
       " '43411 03811 V579 41071 7810 42731',\n",
       " '5990 0389 5109 4820 V5873',\n",
       " '25072 6202 0389 99673 99859 5990 40491 0389',\n",
       " '0088 41071 7802 99681 49121 41401',\n",
       " 'V5811 43310 41400 V5789 41401',\n",
       " '486 51884 5990 4280 03842 42833',\n",
       " '49122 485 42823 41401 5990 4359 03840',\n",
       " '2809 99832 51881 0389 3501 27651 49121',\n",
       " '496 40390 41401 72767 V5789',\n",
       " 'V5789 V5789 5128 5962 40391',\n",
       " '6822 V5789 V5789 49121 5780',\n",
       " '49322 78650 85221 49121 42789',\n",
       " '4439 4592 5990 4280 4241',\n",
       " '41401 41401 4660 3310 42822',\n",
       " '42731 99673 5999 45341 55220 40391 45821 42731 49121 0088 27651',\n",
       " '49121 49121 0389 5070 42821',\n",
       " '51881 486 78659 42731 25043 2761 25080 3910 5770',\n",
       " '03842 51884 7245 3310 59080',\n",
       " '515 5990 41090 5523 49121 42781 5849',\n",
       " '4111 29532 51881 4580 71536 49121 47831',\n",
       " '5849 25043 40391 42831 41011',\n",
       " '9651 25080 49322 4821 45340',\n",
       " '42832 71515 72142 85221 311',\n",
       " '4254 99673 25072 0389 V5789 4580 5770 7824',\n",
       " '41401 5306 82021 4359 45341',\n",
       " '19889 41401 43301 V5789 56089 4414',\n",
       " '44422 5849 99591 78906 99641',\n",
       " '42830 99667 99859 9974 5781',\n",
       " '5849 2375 4829 42823 9975',\n",
       " '5849 3315 486 34830 42823',\n",
       " '42731 486 42821 5119 5070 V5789',\n",
       " '99662 99665 8054 1623 2767 41401',\n",
       " '41401 29620 53290 29663 0088',\n",
       " '51884 5849 2851 486 5070 0389 8208',\n",
       " '73313 4241 45341 8244 1533',\n",
       " '99673 4280 0389 2768 45829',\n",
       " '4271 30421 71536 29654 7226',\n",
       " '41401 0389 42789 73018 71596 42731 44024 1625',\n",
       " 'V551 5849 03810 56985 49121 2767 49121 20280 73027 27801',\n",
       " 'V5789 99859 0088 2767 51884 3310 6824',\n",
       " '2841 56889 49392 6826 73313',\n",
       " '0093 72402 0088 99661 45341 5693',\n",
       " '49121 51881 25080 49121 49121 49121 486',\n",
       " '56941 0389 56081 78820 486 34590',\n",
       " '2776 V5789 30391 56400 56889 34580 29572',\n",
       " '42821 5601 7213 8052 5990',\n",
       " '41401 96502 7907 8208 V5789',\n",
       " 'V5789 2910 41011 8832 78959 41091',\n",
       " '44024 1745 53150 53541 25082 99681 5789 00845',\n",
       " 'V5789 28800 1533 56881 41401 28800',\n",
       " '99859 486 49121 49121 6822 3453',\n",
       " '71536 7847 1972 29690 41051 486',\n",
       " '99889 1125 49122 49121 42843 49121',\n",
       " '29572 82020 29680 42823 0389 5990',\n",
       " '5559 49122 49121 4414 49322 6826 5119',\n",
       " '5934 41071 40390 436 486 4580',\n",
       " '49322 2859 49322 5967 49122',\n",
       " '51881 3383 41081 99649 49121',\n",
       " '0088 45341 73313 49122 42843',\n",
       " '9961 27651 25040 4414 99811',\n",
       " '0389 30300 25013 64313 0389',\n",
       " '03812 27651 V552 7211 5070',\n",
       " '29633 44030 2948 V5332 V5811 42731',\n",
       " '51881 25070 80702 42823 5722 96509 41001 78650',\n",
       " '4271 5566 5849 5569 6826 5845',\n",
       " '33818 71536 78650 1977 03842 5609',\n",
       " '5848 486 27651 4280 51881 1623 0383 53541',\n",
       " '71536 41519 V5789 56211 5990',\n",
       " '41519 5070 4280 41401 99671',\n",
       " '99667 25080 5070 27651 340',\n",
       " '42832 71536 49121 1976 72402',\n",
       " '6826 53642 99591 29660 0539 48242 29532 486',\n",
       " '51881 486 49121 51881 29689',\n",
       " '43311 99661 51881 71591 72210',\n",
       " '0389 9974 5070 29590 99664',\n",
       " '4660 41519 2761 99811 2252',\n",
       " '41071 41071 00845 V5789 5990 8404 486',\n",
       " '5849 41001 0389 4241 49121 6826',\n",
       " '41401 2859 4149 25082 5119 7876 70703',\n",
       " '2948 78701 6826 5109 49121',\n",
       " '41071 0389 82021 25080 486 41071',\n",
       " '49121 49121 99642 V5789 99666',\n",
       " '99666 00845 8082 71536 45341 311',\n",
       " '99664 7907 56213 5849 7242 70710 99673',\n",
       " '4280 7907 49122 42823 71906 99859 51881',\n",
       " '03819 4241 00845 80502 4280',\n",
       " '1976 4241 99662 41401 1623',\n",
       " '53081 5990 0389 5959 496',\n",
       " '5789 9984 4280 486 03811',\n",
       " '41401 34989 82021 51881 2920 1889',\n",
       " '7802 28521 5990 7384 5849',\n",
       " '5921 42731 7802 4280 20026',\n",
       " '4280 5960 41401 78909 29634 99639',\n",
       " '5641 5368 29534 0389 29510',\n",
       " '5849 41071 30301 99859 53541 41402 41400',\n",
       " '56081 42612 V5789 99672 72402',\n",
       " '78659 25060 4911 4941 49121',\n",
       " '6826 23879 78909 99832 20300',\n",
       " '4280 27651 37991 44422 5070',\n",
       " '29383 4589 5849 486 44422',\n",
       " '48242 2767 34590 0380 51881 486 48241 48242',\n",
       " '4280 V5789 4019 41402 1541 43411 29582',\n",
       " '99665 20502 1460 5070 82009',\n",
       " '03842 3332 486 43310 43491 0389',\n",
       " '2809 78009 4280 7242 7802 41400',\n",
       " '4555 56212 4480 7149 49121 20500',\n",
       " '5781 30500 30420 29534 1890',\n",
       " '44021 5990 00845 42822 4271',\n",
       " '41071 6826 4359 5070 25060 45981',\n",
       " '25082 5849 03811 49121 71536',\n",
       " '042 48242 51881 45341 99859 71595 5990 56400 29690 29534',\n",
       " '99661 72210 2767 56081 4580',\n",
       " '41071 99672 5849 73342 4260 99667',\n",
       " '0388 5990 0389 5589 9623',\n",
       " '5849 29534 5070 51883 59010 486 03812',\n",
       " '28262 1539 49321 29189 78097',\n",
       " '78009 71516 25063 V5789 51881 4241 53783',\n",
       " '43310 99859 49122 5070 5990 51881 49121',\n",
       " '25080 99666 1888 2859 7812 4280',\n",
       " '42731 41071 486 486 99669',\n",
       " '486 4280 78909 51884 9221',\n",
       " '71516 486 41400 2851 49121',\n",
       " '30301 V5789 43491 35801 41404 72273',\n",
       " '44022 5849 41031 41031 5990 V553',\n",
       " '41401 2740 56983 49121 99666 4659 5990',\n",
       " '72402 25002 V5789 4280 49121 29620 5579 49322',\n",
       " '03849 42731 42821 5789 41071',\n",
       " '28800 1884 79439 486 41401',\n",
       " '49122 42731 00845 0389 486 4280 V553',\n",
       " '6826 V5789 49122 42823 03810',\n",
       " '00845 4111 71696 78605 4589 41011 99639 490',\n",
       " '6202 4280 5989 2800 2760',\n",
       " '5589 49121 49122 7804 19889 486',\n",
       " '42731 42789 42789 20062 34831 42830 4821',\n",
       " '4280 56213 5770 5589 53541',\n",
       " '486 42831 29534 5762 53782',\n",
       " '5939 1985 4280 29690 0088 7812 49322',\n",
       " '38611 5990 43491 29530 43491 8246',\n",
       " '5070 5781 41071 83905 486',\n",
       " '2411 5789 42823 27651 2800',\n",
       " '2809 41401 8082 8054 72402',\n",
       " '29530 4280 42843 7812 41011 28522',\n",
       " '25080 78097 41071 72283 V5811 56211',\n",
       " '43491 486 6828 78060 2761 5849 99859',\n",
       " '41401 29622 9698 49121 78650 42731',\n",
       " '5750 41519 78039 185 5589',\n",
       " '135 59080 42833 42731 71536 4372',\n",
       " '41401 5849 03811 25080 99672 4829',\n",
       " '4359 5781 5307 5781 8600',\n",
       " '41071 29021 73017 41400 6084 0389',\n",
       " '53019 42843 42831 486 49121 8208',\n",
       " '07999 4941 486 8208 56212 41401',\n",
       " '99639 40491 29574 42789 4280',\n",
       " '496 7230 42731 49121 85222',\n",
       " '4280 29570 2841 99665 490 5362 30470 5990 29680 72252 2851',\n",
       " '8505 42830 486 5550 60499',\n",
       " '41071 99859 44023 79092 99673 6825 4280',\n",
       " '53140 56089 1972 4280 V5811 78901',\n",
       " '486 4280 5990 5589 41401',\n",
       " '42820 0389 4280 V5789 49122 49121 4280',\n",
       " '71536 6824 56985 56031 49122',\n",
       " '486 5119 5570 4280 1970',\n",
       " '40391 40391 27651 57480 03843 25080',\n",
       " '41401 2760 99662 42610 25080 42831',\n",
       " '5990 4280 41031 5601 4359',\n",
       " '71536 5990 486 03843 6826 5849',\n",
       " '4321 72887 40291 485 5130 03840 5990 5712 70703',\n",
       " 'V5789 1983 51881 85181 515',\n",
       " '99859 51181 4111 1976 1508',\n",
       " '5997 99662 42731 43411 41401 53551',\n",
       " '2512 0088 515 43491 4280 43491',\n",
       " '55321 42821 41401 78659 4439 99672',\n",
       " '8208 5609 3310 6159 42732 4294',\n",
       " '7823 7093 42731 51881 486 3942',\n",
       " '57400 4589 25063 42823 25062',\n",
       " '42781 55321 49121 4241 2767 0389 2989 5070',\n",
       " '4359 V5789 99641 70715 2113 7802',\n",
       " '43491 6826 4280 7231 23875',\n",
       " '41401 0539 4241 03842 42731 5119',\n",
       " '7802 4940 42830 48282 43491',\n",
       " '5990 82009 51884 4414 99631 29570 486',\n",
       " '82009 41071 042 41041 5070',\n",
       " '99644 43491 42789 V5789 42843 5180 486',\n",
       " '20300 29650 V5811 5119 99859 29633',\n",
       " '2381 70703 41011 41401 V5789 4660 6826',\n",
       " '27651 2768 41071 57420 9999 53140',\n",
       " '82101 0389 43411 6826 51884',\n",
       " '71535 71536 49121 566 0389',\n",
       " '0388 2948 5789 49122 49121',\n",
       " '4280 5849 99672 5119 0389 5856',\n",
       " '5849 25060 0088 4414 99662 42831',\n",
       " '1629 5715 5601 78652 34830',\n",
       " '45341 33182 5849 8054 29634',\n",
       " '03812 72293 51881 41071 43411',\n",
       " '73313 49392 41400 311 6826 49121 5849',\n",
       " '5772 5569 2761 27651 49121 34982',\n",
       " '41071 41401 8600 7211 5601',\n",
       " '71536 486 7907 1972 5609',\n",
       " '4359 2920 3310 53140 33818',\n",
       " '44024 99662 3310 486 73027',\n",
       " '53500 V5789 2800 6823 43885 5695 28262',\n",
       " '1510 5609 81200 6822 01190',\n",
       " '41071 41071 29564 42823 53240 5990',\n",
       " '5602 42831 486 42731 43310',\n",
       " '486 5856 5070 2913 486 43311 42731',\n",
       " 'V5789 56089 85181 486 99666 27651 30082 8054',\n",
       " '486 42820 5990 6826 78650',\n",
       " '5789 5849 1880 71535 42781 41401 486',\n",
       " '53019 44021 2352 8220 0389',\n",
       " '4372 5990 4439 25062 71536',\n",
       " 'V5789 60001 42654 7802 5609 56081',\n",
       " '51884 4280 5920 25070 44422 0389',\n",
       " '27541 5856 78659 71106 5920 486 311 78650',\n",
       " '42781 99931 5849 34982 V5789 29570 34541',\n",
       " '1745 5070 72889 2859 99656 5609 99859 56212',\n",
       " '5070 4271 V5789 85300 53019 43491 4280 42831 42843',\n",
       " '5789 00845 53783 486 40491',\n",
       " '53240 V5789 V5789 78659 82022 73313 4280',\n",
       " '49121 2851 4439 42781 481 5849 42731 5849',\n",
       " '5849 00845 4870 57400 78652',\n",
       " '30981 29574 25541 20288 71106 29690',\n",
       " '43411 45829 486 57410 4280',\n",
       " '4280 99666 5770 03842 V5789 44022 4280',\n",
       " '29623 42833 99679 5960 78060',\n",
       " '00845 V5789 5733 80009 56081 4359',\n",
       " '99673 42822 9986 3480 34590 45341',\n",
       " '51881 6826 486 41401 486 6826 4555 0389',\n",
       " '49121 29534 4660 4580 49121',\n",
       " '34590 5990 V5811 3180 4821 20500',\n",
       " '48232 2903 57460 53140 5693 6826',\n",
       " '486 34830 2510 3310 49121',\n",
       " '41519 5710 5849 49121 70703 42833',\n",
       " '95203 4280 7210 41011 V5842',\n",
       " '5990 28860 78659 99859 6822',\n",
       " '40390 27651 28522 5579 44021',\n",
       " '25060 27542 99664 25000 99859 4552',\n",
       " '8052 49121 44020 5119 0388',\n",
       " '2766 5789 78039 4280 28984',\n",
       " 'V5789 V5789 51881 41401 45342',\n",
       " '29281 34590 4280 42823 56211',\n",
       " '48241 73342 78906 2967 78659 8052',\n",
       " '45829 4280 40491 29383 0389',\n",
       " 'V5875 43311 5609 5070 99709 00845 4359',\n",
       " 'V5789 71536 486 41071 8056 1513 72761 72252',\n",
       " '7101 00845 78659 56212 4280',\n",
       " '4359 82021 4111 49392 7813',\n",
       " '49121 99674 0389 7230 29654 29570 29530',\n",
       " '4280 V5789 41041 00845 41071',\n",
       " '41401 V5789 V5789 3962 5693',\n",
       " '99673 99673 78650 41401 25060',\n",
       " '7242 28800 5921 5933 29634 0389',\n",
       " '71535 486 7802 5990 5589 5601',\n",
       " '41071 57400 41401 41401 60001 55220 71589 41401',\n",
       " '5185 2740 57420 42833 0270 9920 9721 V5789 0389',\n",
       " '30480 42823 7802 56212 29633 486',\n",
       " '4280 43491 3310 03844 5070 4414 43491',\n",
       " '0088 53100 40390 7213 7802',\n",
       " '29620 25032 5562 35801 5990 2989',\n",
       " '51911 6822 38611 42823 2768 5730',\n",
       " '5990 25002 6184 7802 2768 1122',\n",
       " '5770 56211 60001 56039 28800 25070',\n",
       " '4871 5363 33811 49392 42731',\n",
       " '71536 49121 4280 53100 71536 49121 41401 5070 V5789',\n",
       " '41071 29040 56211 4552 0389',\n",
       " '42731 49121 431 0389 56211',\n",
       " '486 29594 486 311 29530',\n",
       " '53561 5551 7866 25080 5070',\n",
       " '5070 486 29281 0389 79902 5770 25002',\n",
       " '42823 82300 68601 42821 2760 5581 41091',\n",
       " '42731 42732 42731 V571 0389 7802',\n",
       " '43491 72402 4359 4359 4241 27651 3569',\n",
       " '41071 41400 0389 5650 51884 486',\n",
       " '4010 9623 0389 43491 4280 42731',\n",
       " '07999 8248 73007 99662 0389 41071',\n",
       " '03849 7242 V5789 490 48283 2767 0389',\n",
       " '43311 5990 4280 41041 41001',\n",
       " '29664 5789 29530 4280 43491',\n",
       " '44021 2989 71535 51881 73027 5780 486',\n",
       " '78650 99673 5990 5070 25072 5849',\n",
       " '41401 25062 5307 486 5770 78009',\n",
       " '25060 99664 5849 5589 82021',\n",
       " 'V5789 40401 99662 99682 43491 42731',\n",
       " '7812 99662 5100 56212 03849',\n",
       " '72888 8208 8054 41401 29570',\n",
       " '486 4010 4280 99859 4280',\n",
       " '38861 41401 49121 51881 56212 V5789 41071',\n",
       " '44024 42823 73027 V5789 29570',\n",
       " '042 4019 486 49121 42843',\n",
       " '5990 V5789 9961 51881 34830 53291',\n",
       " '5722 41011 29570 29632 29690 2989',\n",
       " '5712 7812 49121 4241 07022 56211',\n",
       " '51881 5185 4280 43491 56989 29620 48242 44021 49121 4280 42731 0389',\n",
       " '78659 51884 29660 29590 51884 29570 71101',\n",
       " '2878 41401 29570 1885 56941 42833',\n",
       " '5589 25070 78900 70704 0389',\n",
       " '99664 25060 5849 99664 25060 28522 5849 5856',\n",
       " '43311 1571 42841 496 4280 99666 03812 6826',\n",
       " '43491 43310 4580 03842 4280',\n",
       " '53783 8248 99646 29570 5750',\n",
       " '5849 5722 40391 51884 5609',\n",
       " '4538 0389 41011 40391 9961 5781',\n",
       " '41519 44021 57420 7802 1892',\n",
       " '99644 56081 72665 41401 99656 99664',\n",
       " '9972 5304 49121 1890 49121 5758',\n",
       " '5601 56089 78079 59080 0389',\n",
       " '42731 49122 7993 78659 78659 4359 43310',\n",
       " '5849 43411 41051 99662 2948',\n",
       " '8080 41071 29570 2948 5651',\n",
       " '03842 8604 03811 51881 V5789 42654',\n",
       " '6826 2740 25040 486 00845 45341',\n",
       " '566 42830 59971 2767 78650 4417 72402 78609 5070 V568',\n",
       " '78652 42840 486 5609 4414',\n",
       " '1972 53783 5849 03811 51881 27651',\n",
       " '70703 5849 5990 99673 35981',\n",
       " '34510 5990 4941 41401 2252 53240 6184',\n",
       " '0389 03843 3310 28521 28241',\n",
       " '0389 43491 42820 25070 5070',\n",
       " '51881 51882 49121 2971 25062',\n",
       " '43411 53240 33392 2767 42823',\n",
       " '1749 1538 25013 5941 1963 515',\n",
       " 'V5789 4401 2948 1533 29530 49121',\n",
       " '7804 42833 42781 03812 45341',\n",
       " '43310 72252 7847 03842 42781',\n",
       " '41401 49122 51881 41091 V5789 41071 43491 99665',\n",
       " '73313 486 55320 7802 6826 4241',\n",
       " '1625 4280 4660 485 486 5368',\n",
       " '41401 4377 4329 85402 53140',\n",
       " '48283 5589 486 0389 5647 99859',\n",
       " '7804 42841 51883 59080 42831 2512 23875 29530 34831',\n",
       " '29620 29570 0380 340 73028 49122 0389',\n",
       " '5849 4280 4019 0389 0389',\n",
       " '9961 0539 4589 25070 4590 49121 5849',\n",
       " '41071 78659 486 42823 486',\n",
       " '515 486 49121 2859 5750 V5789',\n",
       " '00845 56211 3481 78900 V5789 25013',\n",
       " 'V5789 57400 72210 36234 55221',\n",
       " '41400 27651 53350 4660 2768',\n",
       " '2767 41071 41401 8208 72252',\n",
       " '82020 41519 71536 82021 51884 7802',\n",
       " '03842 1625 1991 51881 5990 0389 5849 45341 28800 5770',\n",
       " '99664 41519 5990 20300 3004',\n",
       " '49121 53140 71697 5990 4280',\n",
       " '72252 V571 03849 73342 V5789 V5789',\n",
       " '25080 2800 55091 42823 5921 5849',\n",
       " '8082 4822 8082 41071 5128',\n",
       " '486 70703 29570 51881 25012 49121',\n",
       " '0389 486 29650 49322 25033 486 29690',\n",
       " '42823 V5331 41071 42821 40403 40491',\n",
       " '5789 4870 40291 41071 51884 49121',\n",
       " '71536 4280 49121 4353 4280',\n",
       " '03819 6826 41401 34590 78652 27651',\n",
       " 'V5789 27651 41401 99649 8052 5990 41071',\n",
       " '4778 29620 5715 29633 4280',\n",
       " '71596 59971 7140 39891 5990 29570',\n",
       " '42732 1623 34982 51909 V550 486',\n",
       " '41071 53081 41401 4280 5990',\n",
       " '78652 42732 42823 1541 51189',\n",
       " '28521 486 486 7851 42821 42843',\n",
       " '99642 2989 5990 99859 28262',\n",
       " '82021 V5789 8054 5849 V5789 4359 49121',\n",
       " '28800 71535 29633 1516 27651',\n",
       " '486 3962 5569 4280 05379 0389',\n",
       " '42821 78097 5990 42823 486 99859',\n",
       " '0389 5849 4471 486 0380 49121 99832 40300',\n",
       " '43491 99643 73028 49121 41071',\n",
       " 'V5789 3383 72981 4372 1912',\n",
       " '7802 V5789 42731 8054 78650 27801',\n",
       " '99601 28809 5849 49121 2920 27651',\n",
       " '4871 45340 57400 41401 78650',\n",
       " '486 0383 42843 1623 7907 5070',\n",
       " '5070 41001 5570 V5789 57400 0389',\n",
       " '78659 1741 0539 99667 53783',\n",
       " '5789 44022 53540 34690 9678',\n",
       " '486 78930 486 6826 2851',\n",
       " 'V5789 1888 27549 40491 42741',\n",
       " '56985 41401 73313 4280 55321 5609',\n",
       " '5849 2851 29680 9726 V5789 51881 5990 2536',\n",
       " '41071 5990 56881 99662 45342 0389 41071 8505',\n",
       " '25080 2859 40391 486 99931 486 42983 49122',\n",
       " '43491 43491 78659 40291 2949 42831 4821',\n",
       " '7907 51881 4413 25060 51881',\n",
       " '99677 6822 42789 4280 27651',\n",
       " '6826 6826 53081 5990 7242',\n",
       " '72283 5119 7840 59381 43491',\n",
       " '71536 41401 49121 2800 49121 7802',\n",
       " '481 41401 49322 78097 4870 78659',\n",
       " '49121 7802 41011 42823 49121',\n",
       " '27651 73027 4270 59080 56039 82100 27651',\n",
       " '29680 78650 9694 29643 486 29514',\n",
       " '41401 41401 8052 42823 5849',\n",
       " '0389 486 48283 1529 40390 41041',\n",
       " '8208 1890 486 431 0389',\n",
       " '5789 28489 4280 5602 41401',\n",
       " '9221 5789 311 486 5789',\n",
       " '53081 5781 42832 2767 29534',\n",
       " '0389 99859 5771 6822 51884',\n",
       " '34831 4414 1981 78659 56212',\n",
       " '7224 71536 V5789 41401 78039 2851',\n",
       " '29570 41041 78097 51884 5761',\n",
       " '486 28489 42823 43491 7210 85300',\n",
       " '4920 3453 8056 51884 5990',\n",
       " '49322 00845 33391 42823 49321 03812 30500',\n",
       " '5523 4329 4359 49121 56081',\n",
       " '70707 5781 53140 29623 8244 70710 2800 29660',\n",
       " '70711 4280 49122 29633 0389',\n",
       " '7812 4280 V5789 29570 51884 43491',\n",
       " '27651 1541 30000 25200 0389',\n",
       " '8208 71536 41401 V5789 42833 55220',\n",
       " '43491 35801 82021 78659 4359',\n",
       " '42732 0389 34831 4148 78659 5849 41071',\n",
       " '78659 34591 7907 4928 1543 2113 49122',\n",
       " '78659 6823 25082 27651 2761',\n",
       " '42830 40491 42831 45342 4280',\n",
       " '41401 42731 41011 5849 41071',\n",
       " '45829 78659 5641 27651 486 71596 7100 29620 49121',\n",
       " '29534 70719 42731 49121 29564',\n",
       " '43491 33391 5789 7993 70703',\n",
       " '5589 29650 34831 96509 72888',\n",
       " '5934 5990 82021 1983 82009 41071',\n",
       " '42731 2859 5849 42843 2809 99662 0389',\n",
       " '1700 49322 99661 4610 5770',\n",
       " '5609 7806 56030 1985 42732 7802 49122',\n",
       " '33829 486 29181 78650 42832 7804 486',\n",
       " '49121 03819 4280 49121 81201 5070 42823 5579',\n",
       " '5849 1505 2536 71537 2851 27651 8208',\n",
       " '56081 51884 41401 486 2920',\n",
       " '56211 4552 5990 55229 4660',\n",
       " '29620 29633 71516 56212 49121 53089',\n",
       " '30002 51881 30401 2859 0389 49392 29644',\n",
       " '42789 27651 78650 51881 29633',\n",
       " '486 5849 25012 6826 42781',\n",
       " '4280 49322 53140 2800 43491 99664',\n",
       " '29532 8246 7802 29534 7866 1361',\n",
       " '57450 4558 42731 78650 42840',\n",
       " '5849 25082 81221 99931 6826 27651',\n",
       " '42731 03849 43310 71536 40391',\n",
       " '42731 5849 486 515 29570 5691',\n",
       " '80702 25060 78650 78659 41519',\n",
       " '43491 0389 V5789 41401 42781',\n",
       " '99643 8470 5184 V5789 2888 03842 4260',\n",
       " '82021 78909 53783 2800 2768',\n",
       " '41405 03843 V5789 4139 V5789 85180',\n",
       " '53541 41401 41401 78097 25070 41401',\n",
       " '486 4019 49121 51881 49122',\n",
       " '82302 5990 99644 99666 41401',\n",
       " '25012 V5789 71536 486 515 78039',\n",
       " '41519 96500 41071 34830 49121',\n",
       " '5789 43310 43491 42821 42731',\n",
       " '78659 431 71535 99678 1749 V5789',\n",
       " '29634 0389 29633 29570 5990 49121 28521',\n",
       " '486 4280 V5789 2731 8208 99681 8605 5997 41071',\n",
       " '56211 42789 30302 56081 5601 03849 42832',\n",
       " '5770 53642 42833 29650 51881 29570',\n",
       " '41401 78039 3331 1978 486 4260',\n",
       " '3310 41519 82021 V5789 43491',\n",
       " '42731 220 4280 42731 6824',\n",
       " '42731 41071 V714 70703 566 03842',\n",
       " '43311 4359 1911 34590 3315',\n",
       " '1588 41401 41071 41401 5693 41402',\n",
       " '03842 4019 56089 56211 25080',\n",
       " '2948 43411 1625 78659 3310',\n",
       " '49122 49121 40200 72210 40391',\n",
       " '1551 99811 7907 42731 41071 515',\n",
       " '49121 00845 0389 0389 42789 34550 00845',\n",
       " '41071 4280 5990 4260 42833',\n",
       " '27651 2859 2920 03810 42833 41071',\n",
       " '2859 2760 53140 49121 2859',\n",
       " '4280 9961 7078 42731 1889 42731 6822',\n",
       " '5990 5121 7802 43491 29650',\n",
       " '42833 82021 0389 4820 5921',\n",
       " '41071 V5789 82020 99674 49122',\n",
       " '8244 5921 5722 43491 41401',\n",
       " '53020 71845 99664 78659 40391',\n",
       " '41071 4821 4321 4280 49122',\n",
       " '9690 486 59654 53150 0389 5070',\n",
       " '5990 42830 5070 43491 5859 03849',\n",
       " '0389 4280 99601 5781 49121 42732 99641',\n",
       " 'V5789 49121 5845 56881 56212 29534 60490',\n",
       " '53551 07999 33729 99668 78079 49121',\n",
       " '43491 43491 43310 73313 42731 41400 56211',\n",
       " '0382 49121 56081 7905 V5789',\n",
       " '4280 44022 4292 41401 49121 44024 4280',\n",
       " '5609 0389 4359 41401 5609 25060',\n",
       " '43491 42731 48241 85220 5781 42781',\n",
       " '486 2760 51881 49121 49121',\n",
       " '78900 V5789 9693 2989 V5789 4280 42831',\n",
       " '43411 55220 44024 4359 4280',\n",
       " '2859 8208 99683 8082 03849',\n",
       " '5990 V5789 41071 1891 85221 4359',\n",
       " '53140 0088 78701 4280 V5789 29570',\n",
       " '43491 43491 V5789 85181 42821 1537',\n",
       " '29654 5569 V5789 99647 29582 3310',\n",
       " '4271 0389 03849 56211 41401',\n",
       " '41401 42833 4148 V5811 1579 56211 9971 42732',\n",
       " '49121 486 V5789 42823 42833',\n",
       " '03840 03811 25000 2989 49322',\n",
       " '56400 49121 5722 5849 486',\n",
       " '29633 0389 486 03811 9694',\n",
       " 'V5789 486 56081 V5789 486',\n",
       " '0389 59010 2809 23874 V5789 03842 25082 5601 41401',\n",
       " '5990 7802 41401 5609 20930',\n",
       " '6820 53140 60001 41071 42820',\n",
       " '49121 78903 71591 570 2851',\n",
       " '7248 5990 4359 73689 99642',\n",
       " '42820 0389 5781 8054 5070 43310',\n",
       " '49121 71536 43491 32723 7802 V5789 4280',\n",
       " '78650 70707 486 9982 20300 1991',\n",
       " '41401 99762 41401 42831 5990 42731',\n",
       " '41401 41011 5849 4280 78097',\n",
       " '34831 V5332 5070 85100 99665',\n",
       " '41011 41401 45981 41401 72252',\n",
       " '4401 99673 53510 99673 8248',\n",
       " '0389 78039 71941 44024 99931',\n",
       " '56212 0389 0389 5990 73027',\n",
       " '59080 486 V5789 51881 V5789',\n",
       " '486 41071 1952 41071 29590 V5789 5770 8280 486 71536',\n",
       " '25013 56211 25012 5770 30401',\n",
       " '49121 486 41031 99668 5722 49121 78650',\n",
       " '81200 5990 57410 42831 99666 78659',\n",
       " '71535 49121 5715 4148 5070 7802',\n",
       " '43491 7242 0389 41071 5601 51189 V5789 4280 5849 5070',\n",
       " '42823 5990 71536 V5789 78039 42823',\n",
       " '27651 59010 0389 4280 2989 29504 0389 49122',\n",
       " '486 49121 5781 5920 25070',\n",
       " '43822 1510 4821 4552 9950',\n",
       " '41401 41041 99665 49322 9858',\n",
       " '5070 1976 1534 42731 29534 49121 29690 78791',\n",
       " '43491 V5789 29633 4417 29570 99931',\n",
       " '78901 78791 25070 53240 7802 99673',\n",
       " '82021 41401 99642 78097 30301 9351',\n",
       " '03849 45341 99931 78659 431 25080',\n",
       " '78650 99931 29534 49322 2851',\n",
       " '99672 56081 41071 4010 43491 5609',\n",
       " '27651 51881 486 59080 29041 0389',\n",
       " '42823 0389 1536 49121 41401 5849',\n",
       " '73007 486 42833 49121 49121 41071 486 4829 49121',\n",
       " '0389 V5789 48249 49322 2581',\n",
       " '43491 5306 28529 8072 29620 41071',\n",
       " '42823 41401 486 42731 73313 3313',\n",
       " '43491 49121 5849 3004 2111 42731',\n",
       " '44024 2394 25080 99769 5589',\n",
       " '3310 4280 51881 41071 4414',\n",
       " '43310 73390 5921 0088 41519',\n",
       " '73313 51881 V5789 99673 0389',\n",
       " '27650 42821 5770 5849 99662 486',\n",
       " '42842 43491 0088 41519 5070',\n",
       " '43310 51881 51884 2761 V5789 5070 7804 5070',\n",
       " '25070 42833 42833 99662 78659',\n",
       " '43320 43491 42731 41071 41071 0389',\n",
       " '43491 43491 30390 85221 5849',\n",
       " '486 486 486 42833 78659 486',\n",
       " '4280 25022 44024 78052 5770',\n",
       " '1983 6826 4871 5990 V5789',\n",
       " '20080 29634 4280 2967 5550 5990 7802 5770 0389',\n",
       " '41401 8208 4241 5849 4010 99641',\n",
       " 'V5789 49121 2536 5109 25080 42841 42781',\n",
       " '29660 29633 5770 43491 42789',\n",
       " '82009 56212 25081 5770 72888 45119',\n",
       " '4019 5781 6826 0389 8208 40201',\n",
       " '486 5789 486 49392 27651',\n",
       " '4240 4241 8208 4359 99832',\n",
       " '0389 27651 43300 0088 60001 29570',\n",
       " '51881 5070 41401 51881 7820',\n",
       " '4241 53150 99647 1534 51881',\n",
       " '486 5990 0389 27651 4280',\n",
       " '29570 2920 2859 4359 5990',\n",
       " '4580 57410 30490 5163 29592 78659 0389 53551',\n",
       " '70704 5849 4552 42823 51881 51881 25082',\n",
       " '00845 00845 34590 7812 8911',\n",
       " '7213 34590 5559 99851 5722 78039 3453',\n",
       " '2768 42833 486 486 99662',\n",
       " '49121 60001 7224 49120 5990',\n",
       " '19889 29633 9678 29644 78079 486 2859 5589',\n",
       " '53550 56985 42789 78659 29620',\n",
       " '5991 5849 44022 V5789 2419',\n",
       " '41401 3370 4280 2761 53783',\n",
       " '5715 42731 5990 49121 57451',\n",
       " '42823 4280 41401 49121 99859',\n",
       " '29590 42840 42731 53541 5849 586 45340',\n",
       " '486 0391 4280 78060 V5789',\n",
       " '29574 5990 45981 41519 41081',\n",
       " '25040 486 25080 25012 V5789 41071',\n",
       " '78906 V5789 29570 486 0389 82021',\n",
       " '5070 5715 1976 29570 61801',\n",
       " '29690 29594 042 29663 29653 29570 6826 25040 29680 2989 29633',\n",
       " '486 4280 4280 11284 2989',\n",
       " '42843 99642 51884 73395 41400',\n",
       " '82021 7802 4821 6824 71536',\n",
       " '5715 5849 5307 53784 59010 1623 5990',\n",
       " '41401 70704 73028 5601 5523',\n",
       " '53240 05319 0389 42840 5849 5849 25003',\n",
       " '53550 55220 29570 78039 29570 51884',\n",
       " '5589 486 42831 5990 486',\n",
       " '49121 6826 6826 4660 99662',\n",
       " '1530 6827 44022 73342 486 0389 5990',\n",
       " '3180 42821 49122 51881 57410 8072',\n",
       " '0389 72402 3576 29570 5990',\n",
       " '1972 486 57410 1830 5119',\n",
       " '53340 1541 51881 6823 5770',\n",
       " '5070 71536 5070 5990 9351',\n",
       " '4168 6826 5990 40391 45341',\n",
       " '42823 29574 5849 99662 49122',\n",
       " '41519 4271 51884 41001 49121',\n",
       " '42823 42789 43411 7812 99832',\n",
       " '1977 1579 78079 72402 20040',\n",
       " '27651 70705 0389 0389 41401',\n",
       " '03812 2330 7802 0382 42831 9351',\n",
       " '99939 4280 78791 5762 5185 57400 49121 78900',\n",
       " '5579 03842 4168 5693 0389 58089 56089 45981 5695 99665',\n",
       " '71106 41401 V5811 5990 28803',\n",
       " '42832 40390 53501 99859 27651 486',\n",
       " '0388 56211 78659 29623 5990 0389 9951',\n",
       " '20500 4589 9982 44020 4280',\n",
       " '49121 43491 43491 56211 72252',\n",
       " '51881 2760 49121 78097 56212',\n",
       " '85201 311 0389 34830 29632',\n",
       " '71536 6191 V5789 20500 29570 1623 0389 29570 25000',\n",
       " '5601 49121 29633 51881 486',\n",
       " '0389 4241 42830 45341 41401 71589',\n",
       " '27651 49122 29532 49122 486 78650 78701 5990',\n",
       " '7802 7861 29680 5990 2900 48283',\n",
       " '41401 53550 41401 5990 71595',\n",
       " '82020 41071 41071 71536 486 41071',\n",
       " '03842 1623 5849 4280 43310',\n",
       " '4280 49121 56211 78900 53540',\n",
       " '7384 7820 49121 53081 51881',\n",
       " '8208 29284 V5878 7806 5602 4280 4589 5589',\n",
       " '41071 V5789 25541 5400 56211',\n",
       " '29650 2761 99811 29633 99769',\n",
       " '0389 28800 42833 29570 78659',\n",
       " '42781 49322 5990 51881 4660',\n",
       " '0389 486 4280 53150 73315',\n",
       " '7802 7847 43491 5070 4580',\n",
       " '51881 49322 5601 99641 42731',\n",
       " '6930 2766 25070 4251 41071',\n",
       " '41401 03811 41041 V5789 5990 0389',\n",
       " '44421 78659 486 57400 42789',\n",
       " '0389 25080 72210 78039 59010 5849',\n",
       " '49322 5109 41400 5070 25081 41071 4552',\n",
       " '6822 53240 3310 56081 99672 43491',\n",
       " '78659 1623 5609 8056 486 V5789',\n",
       " '5070 99811 99859 7876 0310 79902',\n",
       " '71536 28489 4870 5579 49390',\n",
       " '8082 4280 79902 99664 68110 99830',\n",
       " 'V5789 42823 78659 496 29633',\n",
       " '29644 29570 2761 0088 29570',\n",
       " '2767 78659 4280 41519 99859 5990 5128',\n",
       " '42781 78097 7802 0389 43491 486 78079 33829 27651',\n",
       " '41401 V5789 5570 0389 99674',\n",
       " '82003 1972 3315 486 2989 29534',\n",
       " '43411 4280 53551 03842 1629 28521',\n",
       " '6826 29634 7384 29570 2859 7804',\n",
       " '0389 2989 1363 32723 41041 49121',\n",
       " '7802 51881 1580 42831 44421',\n",
       " '49121 42731 1623 56212 4280',\n",
       " '03811 48282 56969 485 4279',\n",
       " '8054 27651 0389 49121 2859',\n",
       " '00845 V5789 0389 56212 25070 42823 42833',\n",
       " '85306 V5789 51881 99662 1501',\n",
       " '99859 29530 42821 78909 9694',\n",
       " 'V5789 71535 4538 25080 4829',\n",
       " '5849 42823 4280 486 1749 45341 25022',\n",
       " '4739 6823 41400 45341 6826',\n",
       " '99762 43491 8472 48241 4260 53551 45340',\n",
       " '51881 5680 78659 25080 25080 V5789',\n",
       " '4809 44021 6084 49122 5070 42821',\n",
       " '51881 56211 5849 43491 8249 V5789 4580 5109',\n",
       " '05379 9973 4359 03811 5789 4280 0389',\n",
       " '99662 V5789 0389 82009 0270',\n",
       " '29650 5770 5559 49122 72402 70710 486 5562 1977',\n",
       " '51881 44389 0380 41071 78659 51884',\n",
       " '29690 49121 5849 41519 34590 49322',\n",
       " '486 2733 78079 41401 99666',\n",
       " '78659 55011 20510 0389 5849',\n",
       " '5300 V5789 5789 27651 0382',\n",
       " '4280 4280 49121 42843 41401',\n",
       " '25080 99673 03849 34831 03842 6826 0389 57420',\n",
       " '4589 2766 1625 5856 2761',\n",
       " '25080 99669 99762 5855 42731 0389 44103',\n",
       " '99643 41401 5920 48282 85221',\n",
       " '486 486 42789 3383 42833 85221 V5789',\n",
       " '8208 V5789 5990 49121 4321',\n",
       " 'V5789 4414 78659 0380 41401 0389 0389',\n",
       " '51884 57511 0388 6159 2920',\n",
       " '5609 85225 0389 78659 41400 6826',\n",
       " '1623 V5789 70715 0389 27651 99681 486',\n",
       " '2760 51883 27650 99677 49121 29640 03811',\n",
       " '44101 V5789 2766 1889 73313',\n",
       " '41021 0389 2809 27549 41071 0389',\n",
       " '5856 6826 49121 78659 42833',\n",
       " '41071 25070 7862 V5789 6826 42833',\n",
       " '71536 4329 42789 42831 486 29634',\n",
       " '99672 56081 29042 5198 53140 2859',\n",
       " '4241 41401 70706 78899 5601',\n",
       " '99529 43491 3310 5990 71655 42821 51881 78097 41519',\n",
       " '73313 51881 9100 5771 99643 49322',\n",
       " 'V5331 4280 9642 42731 481 8082 82321',\n",
       " '71536 71536 71536 V5789 7213',\n",
       " '486 4280 27651 4471 5163',\n",
       " '41401 78039 185 43310 78652',\n",
       " '71536 8448 43310 V5789 43411',\n",
       " '44024 V5789 51881 73017 5715 6826',\n",
       " '431 481 486 485 8020 78605',\n",
       " '73393 486 2910 43411 49121 2536 27651 5303 29640 41401',\n",
       " '82111 3481 42830 56211 5128 0380 4280',\n",
       " '41041 72402 41401 72252 42731 78650',\n",
       " '78550 2358 0388 042 042 9961',\n",
       " '71535 V5789 25013 3501 1983',\n",
       " '82009 7230 4139 0389 5789',\n",
       " '2536 03849 29570 42833 42823',\n",
       " '85221 5990 48242 5119 1985',\n",
       " '5849 43491 3698 07999 78039',\n",
       " '30392 35989 78650 34831 92421',\n",
       " '0389 43491 99665 99662 42731',\n",
       " '79902 25080 57510 49322 9916 7802',\n",
       " '30301 V5789 71596 99832 82021 53240',\n",
       " '99673 V5789 41401 07999 78650 8441',\n",
       " '23875 486 0389 43310 78096',\n",
       " '7851 5789 27651 82009 42823 8082',\n",
       " '5849 99673 5849 36816 5849 4271 486 00863 27650',\n",
       " '82003 41071 41401 82021 51884 486',\n",
       " '5579 99673 41401 7806 44023',\n",
       " '41519 25060 1970 73319 34690',\n",
       " '4280 30391 29634 78659 70707 49122',\n",
       " '481 3310 4512 8730 7243 4589',\n",
       " '311 25080 51881 486 2989',\n",
       " '8246 27651 34831 1912 486 1970 5601',\n",
       " '486 53540 71536 5849 2839 41402 042',\n",
       " '44024 29532 42731 44022 96509 5856 41071 56211',\n",
       " '56081 71596 0362 5070 2252',\n",
       " '6826 486 486 7837 51881',\n",
       " '29530 82020 58881 25060 5715',\n",
       " '99769 2809 99931 44422 96509',\n",
       " 'V5789 5856 30480 5997 0389 40391 51881 4821',\n",
       " '486 27650 5849 0389 42789',\n",
       " '0388 07044 042 4280 03842 30390',\n",
       " '42789 4280 4280 99661 53019',\n",
       " '7802 00845 82021 8054 1173 7242',\n",
       " '03811 78650 0389 71596 53010 55321',\n",
       " '431 72210 20500 71515 71536 85221',\n",
       " '42731 42731 4280 6825 0389 1918',\n",
       " '3310 5589 8208 5990 29570',\n",
       " '40291 49122 71536 5849 42831 43491',\n",
       " '5990 82020 4414 486 2252',\n",
       " '42781 51881 25080 41071 44629 49322 42613',\n",
       " '42732 2771 11595 2841 41071',\n",
       " '5781 43491 486 486 486 49122',\n",
       " '5120 7802 78097 5780 31401',\n",
       " '42833 29181 72210 486 49121 29534',\n",
       " '3510 51881 56211 6824 29644 56211',\n",
       " '7802 78551 4280 71536 49322 3510',\n",
       " '25043 5921 1533 5789 27542 78833 1629',\n",
       " '82123 4280 2767 71596 56202 5990',\n",
       " '6825 56039 5601 96500 72888',\n",
       " '99662 486 5070 0389 37854 78097 57400 25060',\n",
       " '1830 V5789 41091 430 4280',\n",
       " '27651 33392 78791 56089 4280 5130',\n",
       " '29623 4280 49322 5770 4659',\n",
       " '57400 03842 51884 4271 42789 22809 55321 71596 00845 5990 00843 40491',\n",
       " '6826 24200 5770 99832 45341',\n",
       " '0389 49121 78097 6826 7866',\n",
       " '1537 29574 29660 25070 4280 2761',\n",
       " '5110 5789 43491 6824 53649 51883 4281 6826',\n",
       " '78903 0389 5849 70706 5570 99931',\n",
       " '49121 43411 41091 51884 42731 29689 42830 99664 29570',\n",
       " '44102 73027 41071 27651 1541',\n",
       " '486 03842 92231 99672 25080 42781',\n",
       " '4589 00845 42833 25063 51881 51881 25072 29570',\n",
       " '4111 25002 7806 311 5990 42731',\n",
       " '25002 0389 51881 29663 7907',\n",
       " '29534 7802 43491 V5789 45340',\n",
       " '2851 41071 40493 5849 44024',\n",
       " '5770 49121 29663 6826 49121',\n",
       " '5609 5849 5849 51881 30490 0389',\n",
       " '43310 42820 6826 7820 2639 43491 5990',\n",
       " '41001 1623 53140 41071 7802',\n",
       " '00845 71595 38869 78659 515',\n",
       " '5990 1541 42830 51884 5990',\n",
       " '79092 5849 99859 8208 V5789 41090 5579 9961',\n",
       " 'V5789 4280 73313 0389 4148 42789',\n",
       " '78009 41401 V5789 34590 44024 73315 43310',\n",
       " '0389 496 1510 25070 51884 5570 53541 0389',\n",
       " '99591 5589 41071 99811 29633',\n",
       " '41041 70715 4280 7802 38611 40491',\n",
       " '6826 51881 4476 44421 V5789',\n",
       " '4557 4580 7802 486 V5789',\n",
       " '51881 486 25082 41071 42823',\n",
       " '0389 4280 56211 51881 V5789',\n",
       " '56211 486 29650 0389 5715',\n",
       " '7244 6820 42823 49322 6827 41401',\n",
       " '311 5921 7802 5990 7802 5609 73027',\n",
       " '5997 5849 42821 41071 4538 49121',\n",
       " '78659 30300 78039 82101 2948',\n",
       " '486 29630 7213 30501 43491',\n",
       " '41401 42833 99762 2740 03811',\n",
       " '486 5070 82123 28521 55221',\n",
       " '40491 44020 5849 5715 53240',\n",
       " '49121 431 53140 5070 71536',\n",
       " '00846 56400 2859 2859 486 5070',\n",
       " '40201 20280 53250 99666 45829 71535',\n",
       " '1983 6826 5845 71536 42731',\n",
       " '82123 99664 486 5770 1541 5589 2800 7234 4280',\n",
       " '25070 25080 56722 27651 99669',\n",
       " '53540 486 27651 4280 4371',\n",
       " '49121 49121 57451 29663 82123 5303 486',\n",
       " '71596 82009 8242 72210 1623',\n",
       " 'V5331 78650 43491 5761 41401',\n",
       " '1726 42830 49121 5849 7197',\n",
       " '25080 82021 0389 57400 51881 40301',\n",
       " '30000 49122 311 29532 99649',\n",
       " '78659 41401 4280 78097 V5042 6826',\n",
       " '20502 5533 4280 56211 3481',\n",
       " '4280 49121 2800 6959 49122',\n",
       " '71595 71695 2740 72402 5601',\n",
       " '40301 51881 41401 0389 99811 53783',\n",
       " '57410 5533 9663 486 4659',\n",
       " '5770 82021 43491 41071 41071 4280',\n",
       " '4271 25040 71595 42731 1970',\n",
       " '6822 1890 82009 49121 78659 0088',\n",
       " '78009 28862 51881 53140 4280',\n",
       " '44024 03843 03842 5789 59080 5849',\n",
       " '4589 5770 30471 82123 0389 4430',\n",
       " '51884 2859 40491 56211 29650',\n",
       " '25080 0389 2800 71596 5070 99859 49121 42821',\n",
       " '44422 2761 3331 1749 2761',\n",
       " '59080 25541 41071 4241 0389 5990 5070',\n",
       " '03849 42731 6826 5601 486',\n",
       " '28529 29570 5070 55221 85220 7384 29644 41071 29189',\n",
       " '1628 1985 V5789 56212 72888 51881',\n",
       " '51881 72252 8208 4280 25070',\n",
       " '4241 0389 2809 43491 5990 25060',\n",
       " '5647 71695 5070 29634 49122',\n",
       " '82120 25012 25002 82021 7806 42731 V5789',\n",
       " '1629 55220 41519 99859 5070',\n",
       " '42789 4359 42731 78659 99584',\n",
       " '42731 41061 5920 78702 4414 5990',\n",
       " '4412 99681 42833 49322 4280',\n",
       " '56983 5589 99667 81301 3453 7802',\n",
       " '5849 00845 56985 41071 49322 25000',\n",
       " '03811 5990 42789 48230 0091',\n",
       " '1561 29594 5990 29690 57470 43491',\n",
       " '4414 27651 V5789 430 57400 99662',\n",
       " '99666 4359 71536 5602 29570',\n",
       " '41071 1588 5849 2948 5070',\n",
       " '5370 40391 4413 99681 5770 5589',\n",
       " '40391 78900 70710 99642 70713 49121',\n",
       " '4928 4280 4241 42781 5070 41071 27651',\n",
       " '5728 29644 9980 V5811 5849 29689 56039',\n",
       " '07999 V5789 4019 59080 72740 71106 41401',\n",
       " '25070 4280 0389 41401 49122',\n",
       " '1623 5550 7230 39891 40390',\n",
       " '57420 5849 7224 4280 4280',\n",
       " '41401 44283 0389 486 43310',\n",
       " '99643 4414 4280 5789 2910 5722 6822 2767 5119',\n",
       " '30480 60784 73342 99678 29623',\n",
       " '72210 7851 42731 3310 68110 49121',\n",
       " '51881 486 5849 00845 25070 45341 78079 0389',\n",
       " '2120 29653 V5789 78650 42731 49121 49121',\n",
       " '29654 1628 29570 49122 78609 43310 4377',\n",
       " '78650 27651 99762 5990 7804',\n",
       " '78097 71591 80701 49121 99939 51881',\n",
       " '5845 56212 4019 5601 4928',\n",
       " '99811 41401 49121 7810 5990',\n",
       " '29574 29594 44023 99677 99681 99666',\n",
       " '5601 25002 0389 41401 53240',\n",
       " '30781 56211 1541 71536 8605',\n",
       " '29623 6982 7840 5715 5609',\n",
       " ...]"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "claims = pd.read_csv('../data/DE1_0_2008_to_2010_Inpatient_Claims_Sample_1.csv')\n",
    "\n",
    "claims_renamed = claims[['DESYNPUF_ID','CLM_ADMSN_DT','ICD9_DGNS_CD_1']]\\\n",
    "    .rename(columns={'DESYNPUF_ID': 'patient', 'CLM_ADMSN_DT': 'date', 'ICD9_DGNS_CD_1':'dx'})\\\n",
    "    .sort_values(['patient', 'date'])\n",
    "\n",
    "print(claims_renamed.head(3))\n",
    "\n",
    "dx_sequences = create_sequences(claims_renamed)\n",
    "\n",
    "dx_sequences = [seq for seq in dx_sequences if len(seq.split()) >  4]\n",
    "\n",
    "dx_sequences\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f234ecdd",
   "metadata": {},
   "source": [
    "We convert our data into Tensors with default batch size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "47efc452",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_distinct_dx = claims_renamed['dx'].nunique()\n",
    "\n",
    "BATCH_SIZE = 32 # default - how many observations per batch that are fed into our NN\n",
    "VOCAB_SIZE = num_distinct_dx # consider all unique diagnoses as vocabulary size\n",
    "MAX_LEN = 3 # max sequence length\n",
    "\n",
    "# Convert to a Tensorflow Dataset\n",
    "sequence_ds = (\n",
    "    tf.data.Dataset.from_tensor_slices(dx_sequences) # converts it into a dataset where each element in the input becomes a separate data point\n",
    "    .batch(BATCH_SIZE)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff3e83bb",
   "metadata": {},
   "source": [
    "This is followed by tokenization. Or converting our diagnosis into numeric values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "7895dd3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original dx sequence\n",
      " 6826 485 4589 7211 49122\n",
      "token representation after appling vectorization layer\n",
      " [ 17 233 111 305]\n"
     ]
    }
   ],
   "source": [
    "# Create a vectorisation layer\n",
    "vectorize_layer = layers.TextVectorization(\n",
    "    standardize=\"lower\", # This converts our text to lowercase, note some dx contain strings. \n",
    "    max_tokens=VOCAB_SIZE, # gives the most prevalent dx an integer token\n",
    "    output_mode=\"int\",\n",
    "    output_sequence_length=MAX_LEN + 1, # max length of each of our sequences + 1\n",
    ")\n",
    "\n",
    "# Adapt the layer to the training set\n",
    "vectorize_layer.adapt(sequence_ds)\n",
    "\n",
    "vocab = vectorize_layer.get_vocabulary()  # To get words back from token indices\n",
    "\n",
    "# Display the same example converted to ints\n",
    "example_tokenised = vectorize_layer(dx_sequences[0])\n",
    "print(\"original dx sequence\\n\",dx_sequences[0])\n",
    "print(\"token representation after appling vectorization layer\\n\",example_tokenised.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5afbc16",
   "metadata": {},
   "source": [
    "Prepare our data.\n",
    "\n",
    "Example: \n",
    "\n",
    "222 -> predict 1112\n",
    "\n",
    "222 + 1112 -> predict 377\n",
    "\n",
    "222 + 1112 + 377 -> predict 725"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "6a331511",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Input (x): [ 17 233 111]\n",
      "First Target (y): [233 111 305]\n"
     ]
    }
   ],
   "source": [
    "def prepare_inputs(text):\n",
    "    \"\"\"\n",
    "    Shift word sequences by 1 position so that the target for position (i) is\n",
    "    word at position (i+1). The model will use all words up till position (i)\n",
    "    to predict the next word.\n",
    "    \"\"\"\n",
    "    text = tf.expand_dims(text, -1)\n",
    "    tokenized_sentences = vectorize_layer(text)\n",
    "    x = tokenized_sentences[:, :-1] # contains all tokens except the last one in each sequence\n",
    "    y = tokenized_sentences[:, 1:] # contains all tokens except the first one, effectively shifting the sequence by one position\n",
    "    return x, y\n",
    "\n",
    "train_ds = sequence_ds.map(prepare_inputs)\n",
    "\n",
    "for x, y in train_ds.take(1):  # Get first batch\n",
    "    print(\"First Input (x):\", x[0].numpy())  # First observation\n",
    "    print(\"First Target (y):\", y[0].numpy()) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a02b8c09",
   "metadata": {},
   "source": [
    "# Creating a model object"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da207260",
   "metadata": {},
   "source": [
    "This step will use Keras API and allows us to predefine our layers, but before that lets define our objects for embedding, attention mask, and transformer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c75befc8",
   "metadata": {},
   "source": [
    "### Embeddings\n",
    "\n",
    "We create numeric representations of our tokens that also encode position. This creates a distinct vector per diagnosis code. At this point this is a map of our existing token and a vanilla version of our diagnosis that represents only that specific icd 10 codes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "a87e2033",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TokenAndPositionEmbedding(layers.Layer):\n",
    "    def __init__(self, maxlen, vocab_size, embed_dim):\n",
    "        super().__init__()\n",
    "        self.token_emb = layers.Embedding(input_dim=vocab_size, output_dim=embed_dim)\n",
    "        self.pos_emb = layers.Embedding(input_dim=maxlen, output_dim=embed_dim)\n",
    "\n",
    "    def call(self, x):\n",
    "        maxlen = ops.shape(x)[-1]\n",
    "        positions = ops.arange(0, maxlen, 1)\n",
    "        positions = self.pos_emb(positions)\n",
    "        x = self.token_emb(x)\n",
    "        return x + positions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19d0071f",
   "metadata": {},
   "source": [
    "###  Attention mask\n",
    "\n",
    "Prevents our model from peeking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "d60578bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def causal_attention_mask(batch_size, n_dest, n_src, dtype):\n",
    "    \"\"\"\n",
    "    Mask the upper half of the dot product matrix in self attention.\n",
    "    This prevents flow of information from future tokens to current token.\n",
    "    1's in the lower triangle, counting from the lower right corner.\n",
    "    \"\"\"\n",
    "    i = ops.arange(n_dest)[:, None]\n",
    "    j = ops.arange(n_src)\n",
    "    m = i >= j - n_src + n_dest\n",
    "    mask = ops.cast(m, dtype)\n",
    "    mask = ops.reshape(mask, [1, n_dest, n_src])\n",
    "    mult = ops.concatenate(\n",
    "        [ops.expand_dims(batch_size, -1), ops.convert_to_tensor([1, 1])], 0\n",
    "    )\n",
    "    return ops.tile(mask, mult)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "977a26d1",
   "metadata": {},
   "source": [
    "### Transformer\n",
    "\n",
    "This piece is what makes the gpt world go round and round. \n",
    "\n",
    "Given our short sequence.\n",
    "\n",
    "dx sequence: 1970 6186\n",
    "\n",
    "Lets focus on our last diagnosis code for this sequence. \n",
    "\n",
    "We create an embedding called A for diagnosis code 6186. This differs from our original embedding created above which we will call Z. \n",
    "\n",
    "The goal is to encode additional information from diagnosis codes 1970 and itself, or 6186. To do this we create embeddings B and C respectively. This helps us understand the proportion of diagnosis code 6186 will be updated in terms of meaning by B (1970) and itself (6186).\n",
    "\n",
    "We take these proportions and apply them to new embeddings, also called values, for our diagnosis called D and F to return masked self attention values. This is then added to our original embedding (Z). This output is then fed into our neural network for further refinement. There are many ways to understand this next step, easiest way to understand this is through a mathematical lense, these are simply nested functions. These neural networks may capture macro level patterns, such as episodes or encounters associated with groups of diagnosis codes, and as we add additional hidden layers captures micro patterns between our diagnosis codes.\n",
    "\n",
    "What this means in clinical terms, ICD 6186 is for small bowel prolapse. This could occur due to child birth or prior surgeries. The meaning of our embedding would change depending on patients sequence of diagnosis codes. 6186 might have its meaning updated by diagnosis code embeddings for delivery, while others for surgeries. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "01ac04dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerBlock(layers.Layer):\n",
    "    def __init__(self, EMBED_DIM, NUM_HEADS, FEED_FOWARD_DIM, rate=0.1):\n",
    "        super().__init__()\n",
    "        self.att = layers.MultiHeadAttention(NUM_HEADS, EMBED_DIM)\n",
    "        self.ffn = keras.Sequential(\n",
    "            [\n",
    "                layers.Dense(FEED_FOWARD_DIM, activation=\"relu\"), # hidden layer\n",
    "                layers.Dense(EMBED_DIM), # output layer \n",
    "            ]\n",
    "        )\n",
    "        self.layernorm1 = layers.LayerNormalization(epsilon=1e-6) # scale\n",
    "        self.layernorm2 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.dropout1 = layers.Dropout(rate) # drop some neurons to prevent overfitting\n",
    "        self.dropout2 = layers.Dropout(rate)\n",
    "\n",
    "    def call(self, inputs): \n",
    "        input_shape = ops.shape(inputs)\n",
    "        batch_size = input_shape[0] # determine batch size\n",
    "        seq_len = input_shape[1] # determine input/embeddng size, assumes the same?\n",
    "        causal_mask = causal_attention_mask(batch_size, seq_len, seq_len, \"bool\")\n",
    "        attention_output = self.att(inputs, inputs, attention_mask=causal_mask)\n",
    "        attention_output = self.dropout1(attention_output)\n",
    "        out1 = self.layernorm1(inputs + attention_output)\n",
    "        ffn_output = self.ffn(out1)\n",
    "        ffn_output = self.dropout2(ffn_output)\n",
    "        return self.layernorm2(out1 + ffn_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2b33f78",
   "metadata": {},
   "source": [
    "Lets build our model obect! This approach creates a sequence of layers, and does not actually train or run anything, your essentially predefining your steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "31b0de89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_15\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_15\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ token_and_position_embedding_7  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)           │         <span style=\"color: #00af00; text-decoration-color: #00af00\">5,486</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TokenAndPositionEmbedding</span>)     │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ transformer_block_7             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)           │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,358</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerBlock</span>)              │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_23 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2740</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,220</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_14 (\u001b[38;5;33mInputLayer\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)              │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ token_and_position_embedding_7  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m2\u001b[0m)           │         \u001b[38;5;34m5,486\u001b[0m │\n",
       "│ (\u001b[38;5;33mTokenAndPositionEmbedding\u001b[0m)     │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ transformer_block_7             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m2\u001b[0m)           │         \u001b[38;5;34m1,358\u001b[0m │\n",
       "│ (\u001b[38;5;33mTransformerBlock\u001b[0m)              │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_23 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m2740\u001b[0m)        │         \u001b[38;5;34m8,220\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">15,064</span> (58.84 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m15,064\u001b[0m (58.84 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">15,064</span> (58.84 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m15,064\u001b[0m (58.84 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "BATCH_SIZE = 32 # default - how many observations per batch that are fed into our NN\n",
    "VOCAB_SIZE = num_distinct_dx # only consider top 10000 dx by volume\n",
    "MAX_LEN = 3 # max sequence length\n",
    "EMBED_DIM = 2 # embedding size for each token\n",
    "NUM_HEADS = 3\n",
    "FEED_FOWARD_DIM= 256  # Hidden layer size in feed forward network inside transformer\n",
    "\n",
    "\n",
    "inputs = layers.Input(shape=(MAX_LEN,), dtype=\"int32\") # input layer\n",
    "\n",
    "embedding_layer = TokenAndPositionEmbedding(MAX_LEN, VOCAB_SIZE, EMBED_DIM)\n",
    "\n",
    "x = embedding_layer(inputs)\n",
    "\n",
    "transformer_block = TransformerBlock(EMBED_DIM, NUM_HEADS, FEED_FOWARD_DIM) # ATTENTION LAYER + HIDDEN LAYER (NN)\n",
    "\n",
    "x = transformer_block(x)\n",
    "\n",
    "outputs = layers.Dense(VOCAB_SIZE)(x) \n",
    "\n",
    "model = models.Model(inputs=inputs, outputs=[outputs, x]) \n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f9e06be",
   "metadata": {},
   "source": [
    "Additional steps, we include additional require components: loss function, optimizer, and performance metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "7119b455",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "\n",
    "model.compile(\n",
    "        optimizer = \"adam\",\n",
    "        loss=[loss_fn, None]\n",
    "    ) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41734e3e",
   "metadata": {},
   "source": [
    "Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "12de467e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "56/56 - 0s - 4ms/step - loss: 5.9255\n",
      "Epoch 2/25\n",
      "56/56 - 0s - 4ms/step - loss: 5.8822\n",
      "Epoch 3/25\n",
      "56/56 - 0s - 4ms/step - loss: 5.8624\n",
      "Epoch 4/25\n",
      "56/56 - 0s - 4ms/step - loss: 5.8475\n",
      "Epoch 5/25\n",
      "56/56 - 0s - 4ms/step - loss: 5.8337\n",
      "Epoch 6/25\n",
      "56/56 - 0s - 4ms/step - loss: 5.8261\n",
      "Epoch 7/25\n",
      "56/56 - 0s - 4ms/step - loss: 5.8253\n",
      "Epoch 8/25\n",
      "56/56 - 0s - 5ms/step - loss: 5.8189\n",
      "Epoch 9/25\n",
      "56/56 - 0s - 4ms/step - loss: 5.8150\n",
      "Epoch 10/25\n",
      "56/56 - 0s - 4ms/step - loss: 5.8165\n",
      "Epoch 11/25\n",
      "56/56 - 0s - 4ms/step - loss: 5.8132\n",
      "Epoch 12/25\n",
      "56/56 - 0s - 4ms/step - loss: 5.8143\n",
      "Epoch 13/25\n",
      "56/56 - 0s - 4ms/step - loss: 5.8125\n",
      "Epoch 14/25\n",
      "56/56 - 0s - 4ms/step - loss: 5.8114\n",
      "Epoch 15/25\n",
      "56/56 - 0s - 4ms/step - loss: 5.8115\n",
      "Epoch 16/25\n",
      "56/56 - 0s - 4ms/step - loss: 5.8061\n",
      "Epoch 17/25\n",
      "56/56 - 0s - 4ms/step - loss: 5.8043\n",
      "Epoch 18/25\n",
      "56/56 - 0s - 4ms/step - loss: 5.8021\n",
      "Epoch 19/25\n",
      "56/56 - 0s - 4ms/step - loss: 5.8042\n",
      "Epoch 20/25\n",
      "56/56 - 0s - 4ms/step - loss: 5.8044\n",
      "Epoch 21/25\n",
      "56/56 - 0s - 4ms/step - loss: 5.8045\n",
      "Epoch 22/25\n",
      "56/56 - 0s - 4ms/step - loss: 5.8028\n",
      "Epoch 23/25\n",
      "56/56 - 0s - 4ms/step - loss: 5.8010\n",
      "Epoch 24/25\n",
      "56/56 - 0s - 4ms/step - loss: 5.8035\n",
      "Epoch 25/25\n",
      "56/56 - 0s - 4ms/step - loss: 5.8020\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1cb0ec2c400>"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_ds, verbose=2, epochs=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "60dac7f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "loss = model.history.history['loss']\n",
    "epochs = range(1, len(loss) + 1)\n",
    "\n",
    "plt.plot(epochs, loss, 'b-', label='Training loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training Loss Across Epochs')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15c79d48",
   "metadata": {},
   "source": [
    "Lets test our model out! With only too epochs and too small context window we expect it to perform poorly.\n",
    "\n",
    "We have to convert our input into model readable input, so lets recycle our vectorize_layer().\n",
    "\n",
    "Test example from our training set. '6826 485 4589 7211 49122'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "fe0878be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4,), dtype=int64, numpy=array([ 17, 233, 111,   0], dtype=int64)>"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_prompt = \"6826 485 4589\"\n",
    "\n",
    "tokenized_example = vectorize_layer(start_prompt)\n",
    "\n",
    "tokenized_example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaa17876",
   "metadata": {},
   "source": [
    "Since we are not running batches and only a single observation, lets make some adjustments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "5a4c4662",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = tokenized_example[:MAX_LEN]\n",
    "\n",
    "x = np.expand_dims(tokens, axis=0)\n",
    "\n",
    "y_pred, attention_scores = model.predict(x, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13e49fa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token: 486, Probability: 4.0302\n",
      "Token: v5789, Probability: 3.8886\n",
      "Token: 4280, Probability: 3.8728\n",
      "Token: 0389, Probability: 3.7248\n",
      "Token: 49121, Probability: 3.6444\n"
     ]
    }
   ],
   "source": [
    "# Get the probabilities for the next token\n",
    "next_token_probs = y_pred[0][len(start_prompt.split())-1]  # position after your input\n",
    "\n",
    "# Show top 5 predictions\n",
    "k = 5\n",
    "top_k_indices = np.argsort(next_token_probs)[-k:][::-1]\n",
    "for idx in top_k_indices:\n",
    "    print(f\"Diagnosis Code: {vocab[idx]}, Probability: {next_token_probs[idx]:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
