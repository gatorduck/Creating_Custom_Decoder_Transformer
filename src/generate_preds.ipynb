{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "747ccffa",
   "metadata": {},
   "source": [
    "Lets load our model and generate new predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39509df9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\marti\\OneDrive\\workspaces\\github_repos\\Creating_Custom_Decoder_Transformer\\venv\\lib\\site-packages\\keras\\src\\saving\\saving_lib.py:802: UserWarning: Skipping variable loading for optimizer 'adam', because it has 42 variables whereas the saved optimizer has 2 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    }
   ],
   "source": [
    "# Load the combined healthcare transformer model\n",
    "import tensorflow as tf\n",
    "from keras import models\n",
    "import numpy as np\n",
    "from custom_layers import TokenAndPositionEmbedding, TransformerBlock\n",
    "\n",
    "\n",
    "try:\n",
    "    # Load the combined model (includes text vectorization + transformer)\n",
    "    model = models.load_model('../models/healthcare_transformer.keras')\n",
    "    \n",
    "    # Extract vocabulary from the vectorization layer\n",
    "    for layer in model.layers:\n",
    "        if hasattr(layer, 'get_vocabulary'):\n",
    "            vocab = layer.get_vocabulary()\n",
    "            break\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error loading model: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fe89258e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor shape: (1,)\n",
      "Model output shape: (1, 3, 2740)\n",
      "Current sequence length: 2\n",
      "Getting predictions from position: 2\n",
      "Probability vector shape: (2740,)\n",
      "\n",
      "Top 5 next diagnosis predictions:\n",
      "1. 486: 3.2188\n",
      "2. 4280: 3.1891\n",
      "3. 0389: 2.9358\n",
      "4. 51881: 2.9218\n",
      "5. v5789: 2.8318\n",
      "\n",
      "Best prediction: 486 (probability: 3.2188)\n",
      "Extended sequence: 6826 485 486\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Input diagnosis sequence\n",
    "diagnosis_sequence = \"6826 485\"\n",
    "\n",
    "# Convert to tensor\n",
    "text_tensor = tf.constant([diagnosis_sequence])\n",
    "print(f\"Tensor shape: {text_tensor.shape}\")\n",
    "\n",
    "# Get model predictions\n",
    "predictions = model.predict(text_tensor, verbose=0)\n",
    "if isinstance(predictions, list):\n",
    "    y_pred = predictions[0]\n",
    "else:\n",
    "    y_pred = predictions\n",
    "\n",
    "print(f\"Model output shape: {y_pred.shape}\")\n",
    "\n",
    "# Get probabilities for next token\n",
    "current_length = len(diagnosis_sequence.split())\n",
    "print(f\"Current sequence length: {current_length}\")\n",
    "print(f\"Getting predictions from position: {current_length}\")\n",
    "\n",
    "next_token_probs = y_pred[0][current_length]\n",
    "print(f\"Probability vector shape: {next_token_probs.shape}\")\n",
    "\n",
    "# Get top 5 predictions\n",
    "k = 5\n",
    "top_5_indices = np.argsort(next_token_probs)[-k:][::-1]\n",
    "top_5_probs = next_token_probs[top_5_indices]\n",
    "\n",
    "print(f\"\\nTop {k} next diagnosis predictions:\")\n",
    "for i, (idx, prob) in enumerate(zip(top_5_indices, top_5_probs)):\n",
    "    diagnosis_code = vocab[idx] if idx < len(vocab) else f\"Token_{idx}\"\n",
    "    print(f\"{i+1}. {diagnosis_code}: {prob:.4f}\")\n",
    "\n",
    "# Get the best prediction (argmax)\n",
    "best_idx = top_5_indices[0]\n",
    "best_code = vocab[best_idx] if best_idx < len(vocab) else f\"Token_{best_idx}\"\n",
    "best_prob = top_5_probs[0]\n",
    "\n",
    "print(f\"\\nBest prediction: {best_code} (probability: {best_prob:.4f})\")\n",
    "print(f\"Extended sequence: {diagnosis_sequence} {best_code}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dea8144f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simple Healthcare Diagnosis Predictor\n",
      "========================================\n",
      "\n",
      "Input: '6826'\n",
      "Top 3 predictions:\n",
      "  1. 486: 3.2188\n",
      "  2. 4280: 3.1891\n",
      "  3. 0389: 2.9358\n",
      "\n",
      "Input: '6826 485'\n",
      "Top 3 predictions:\n",
      "  1. 486: 3.2188\n",
      "  2. 4280: 3.1891\n",
      "  3. 0389: 2.9358\n",
      "\n",
      "Input: '1970'\n",
      "Top 3 predictions:\n",
      "  1. 486: 3.2188\n",
      "  2. 4280: 3.1891\n",
      "  3. 0389: 2.9358\n"
     ]
    }
   ],
   "source": [
    "# Simple prediction script\n",
    "def simple_predict(diagnosis_sequence, top_k=5):\n",
    "    \"\"\"\n",
    "    Simple function to get next diagnosis predictions.\n",
    "    \n",
    "    Args:\n",
    "        diagnosis_sequence: String of diagnosis codes (e.g., \"6826 485\")\n",
    "        top_k: Number of top predictions to return\n",
    "    \n",
    "    Returns:\n",
    "        List of (diagnosis_code, probability) tuples\n",
    "    \"\"\"\n",
    "    # Convert to tensor\n",
    "    text_tensor = tf.constant([diagnosis_sequence])\n",
    "    \n",
    "    # Get predictions\n",
    "    predictions = model.predict(text_tensor, verbose=0)\n",
    "    if isinstance(predictions, list):\n",
    "        y_pred = predictions[0]\n",
    "    else:\n",
    "        y_pred = predictions\n",
    "    \n",
    "    # Get probabilities for next token\n",
    "    current_length = len(diagnosis_sequence.split())\n",
    "    if current_length >= y_pred.shape[1]:\n",
    "        print(f\"Warning: Sequence too long ({current_length} >= {y_pred.shape[1]})\")\n",
    "        return []\n",
    "    \n",
    "    next_token_probs = y_pred[0][current_length]\n",
    "    \n",
    "    # Get top-k predictions\n",
    "    top_k_indices = np.argsort(next_token_probs)[-top_k:][::-1]\n",
    "    top_k_probs = next_token_probs[top_k_indices]\n",
    "    \n",
    "    # Convert to diagnosis codes\n",
    "    results = []\n",
    "    for idx, prob in zip(top_k_indices, top_k_probs):\n",
    "        if idx < len(vocab):\n",
    "            code = vocab[idx]\n",
    "            if code and code not in ['', '[UNK]', '[PAD]']:\n",
    "                results.append((code, float(prob)))\n",
    "        \n",
    "    return results\n",
    "\n",
    "# Test examples\n",
    "print(\"Simple Healthcare Diagnosis Predictor\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "test_cases = [\n",
    "    \"6826\",\n",
    "    \"6826 485\", \n",
    "    \"1970\"\n",
    "]\n",
    "\n",
    "for test_seq in test_cases:\n",
    "    print(f\"\\nInput: '{test_seq}'\")\n",
    "    predictions = simple_predict(test_seq, top_k=3)\n",
    "    print(\"Top 3 predictions:\")\n",
    "    for i, (code, prob) in enumerate(predictions, 1):\n",
    "        print(f\"  {i}. {code}: {prob:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a241921f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def iterative_diagnosis_prediction_v2(initial_sequence, num_iterations=5, show_progress=True):\n",
    "    \"\"\"\n",
    "    Improved iterative prediction using cleaner numpy logic.\n",
    "    \n",
    "    Args:\n",
    "        initial_sequence: Starting diagnosis codes (e.g., \"6826 485 4589\")\n",
    "        num_iterations: Number of prediction iterations to perform\n",
    "        show_progress: Whether to display the prediction process\n",
    "    \n",
    "    Returns:\n",
    "        Final extended sequence and prediction history\n",
    "    \"\"\"\n",
    "    \n",
    "    current_sequence = initial_sequence.strip()\n",
    "    prediction_history = []\n",
    "    \n",
    "    print(f\"Starting iterative prediction from: '{current_sequence}'\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    for iteration in range(num_iterations):\n",
    "        try:\n",
    "            # Convert current sequence to tensor\n",
    "            text_tensor = tf.constant([current_sequence])\n",
    "            \n",
    "            # Get model predictions (including attention scores if available)\n",
    "            predictions = model.predict(text_tensor, verbose=0)\n",
    "            \n",
    "            # Handle multiple outputs (predictions and attention scores)\n",
    "            if isinstance(predictions, list):\n",
    "                y_pred = predictions[0]\n",
    "                attention_scores = predictions[1] if len(predictions) > 1 else None\n",
    "            else:\n",
    "                y_pred = predictions\n",
    "                attention_scores = None\n",
    "            \n",
    "            # Get the probabilities for the next token (at the position after input)\n",
    "            next_token_probs = y_pred[0][len(current_sequence.split())-1]\n",
    "            \n",
    "            # Get top-5 predictions using numpy argsort (cleaner approach)\n",
    "            k = 5\n",
    "            top_5_indices = np.argsort(next_token_probs)[-k:][::-1]\n",
    "            top_5_probs = next_token_probs[top_5_indices]\n",
    "            \n",
    "            # Convert indices to diagnosis codes\n",
    "            top_5_codes = []\n",
    "            for idx, prob in zip(top_5_indices, top_5_probs):\n",
    "                if idx < len(vocab):\n",
    "                    code = vocab[idx]\n",
    "                    if code and code not in ['', '[UNK]', '[PAD]']:\n",
    "                        top_5_codes.append((code, float(prob)))\n",
    "                    else:\n",
    "                        top_5_codes.append((f\"Unknown_{idx}\", float(prob)))\n",
    "                else:\n",
    "                    top_5_codes.append((f\"Token_{idx}\", float(prob)))\n",
    "            \n",
    "            # Get the selected diagnosis code (argmax)\n",
    "            selected_code = top_5_codes[0][0] if top_5_codes else vocab[top_5_indices[0]]\n",
    "            \n",
    "            if show_progress:\n",
    "                print(f\"\\nIteration {iteration + 1}:\")\n",
    "                print(f\"Current sequence: {current_sequence}\")\n",
    "                print(f\"Top 5 next predictions:\")\n",
    "                for i, (code, prob) in enumerate(top_5_codes):\n",
    "                    print(f\"Diagnosis Code: {code}, Probability: {prob:.4f}\")\n",
    "                print(f\"Selected (argmax): {selected_code}\")\n",
    "                       \n",
    "            # Store prediction info\n",
    "            step_info = {\n",
    "                'iteration': iteration + 1,\n",
    "                'input_sequence': current_sequence,\n",
    "                'top_5_predictions': top_5_codes,\n",
    "                'selected_code': selected_code,\n",
    "                'confidence': float(top_5_probs[0]),\n",
    "                'attention_scores': attention_scores\n",
    "            }\n",
    "            prediction_history.append(step_info)\n",
    "            \n",
    "            # Append selected code to sequence\n",
    "            current_sequence += f\" {selected_code}\"\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error in iteration {iteration + 1}: {e}\")\n",
    "            break\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(f\"Final sequence: {current_sequence}\")\n",
    "    print(f\"Extended from {len(initial_sequence.split())} to {len(current_sequence.split())} codes\")\n",
    "    \n",
    "    return current_sequence, prediction_history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e19dcfd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting iterative prediction from: '6826'\n",
      "============================================================\n",
      "\n",
      "Iteration 1:\n",
      "Current sequence: 6826\n",
      "Top 5 next predictions:\n",
      "Diagnosis Code: 486, Probability: 3.2188\n",
      "Diagnosis Code: 4280, Probability: 3.1891\n",
      "Diagnosis Code: 0389, Probability: 2.9358\n",
      "Diagnosis Code: 51881, Probability: 2.9218\n",
      "Diagnosis Code: v5789, Probability: 2.8318\n",
      "Selected (argmax): 486\n",
      "\n",
      "Iteration 2:\n",
      "Current sequence: 6826 486\n",
      "Top 5 next predictions:\n",
      "Diagnosis Code: 486, Probability: 3.2188\n",
      "Diagnosis Code: 4280, Probability: 3.1891\n",
      "Diagnosis Code: 0389, Probability: 2.9358\n",
      "Diagnosis Code: 51881, Probability: 2.9218\n",
      "Diagnosis Code: v5789, Probability: 2.8318\n",
      "Selected (argmax): 486\n",
      "\n",
      "Iteration 3:\n",
      "Current sequence: 6826 486 486\n",
      "Top 5 next predictions:\n",
      "Diagnosis Code: 486, Probability: 3.2188\n",
      "Diagnosis Code: 4280, Probability: 3.1891\n",
      "Diagnosis Code: 0389, Probability: 2.9358\n",
      "Diagnosis Code: 51881, Probability: 2.9218\n",
      "Diagnosis Code: v5789, Probability: 2.8318\n",
      "Selected (argmax): 486\n",
      "Error in iteration 4: index 3 is out of bounds for axis 0 with size 3\n",
      "\n",
      "============================================================\n",
      "Final sequence: 6826 486 486 486\n",
      "Extended from 1 to 4 codes\n",
      "Error in iteration 4: index 3 is out of bounds for axis 0 with size 3\n",
      "\n",
      "============================================================\n",
      "Final sequence: 6826 486 486 486\n",
      "Extended from 1 to 4 codes\n"
     ]
    }
   ],
   "source": [
    "# Test it\n",
    "final_seq, history = iterative_diagnosis_prediction_v2('6826', num_iterations=5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
